{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Myt3nXoISkh",
    "outputId": "61edb207-555b-4de5-fe2f-47ae8661784c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\henrique\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dsUdjzn-JJgR"
   },
   "outputs": [],
   "source": [
    "def palvavra_separadas(dados, len_palavras = 2):\n",
    "  '''\n",
    "  ******************************************************************************\n",
    "  palvavra_separadas: Separa as palavras com mais de\n",
    "  len_palavras caracteres, retirando pontuacoes.\n",
    "  ------------------------------------------------------------------------------\n",
    "  Input:\n",
    "  ------------------------------------------------------------------------------\n",
    "  dados: Datafame\n",
    "  len_palavras : tamanho minimo das palavras que seram considerado (>2)\n",
    "  ------------------------------------------------------------------------------\n",
    "  Outout:\n",
    "  ------------------------------------------------------------------------------\n",
    "  tokens: listas com as palavras separadas\n",
    "  ------------------------------------------------------------------------------\n",
    "  ******************************************************************************\n",
    "  '''\n",
    "  tokens = []\n",
    "  for frase in dados[\"tratados\"]:\n",
    "    for token in nltk.tokenize.word_tokenize(frase):\n",
    "      if token.isalpha() and len(token) > len_palavras:\n",
    "        tokens.append(token.lower())\n",
    "\n",
    "  return tokens\n",
    "\n",
    "def gera_palavras_unicas(palavras):\n",
    "  '''\n",
    "  ******************************************************************************\n",
    "  gera_palavras_unicas: Gera conjunto com palavras unicas.\n",
    "  ------------------------------------------------------------------------------\n",
    "  Input:\n",
    "  ------------------------------------------------------------------------------\n",
    "  palavra: lista com as palavras  \n",
    "  ------------------------------------------------------------------------------\n",
    "  Outout:\n",
    "  ------------------------------------------------------------------------------\n",
    "  tokens: listas com as palavras separadas\n",
    "  ------------------------------------------------------------------------------\n",
    "  ******************************************************************************\n",
    "  '''\n",
    "  unicas = set()\n",
    "\n",
    "  for palavra in palavras:\n",
    "    unicas.add(palavra)\n",
    "\n",
    "  return unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_Dh8xfGUL2E5"
   },
   "outputs": [],
   "source": [
    "def substituir(dados):\n",
    "  '''\n",
    "  ******************************************************************************\n",
    "  Tratando a base de dados.\n",
    "  ------------------------------------------------------------------------------\n",
    "  Input:\n",
    "  ------------------------------------------------------------------------------\n",
    "  dados: Datafame original\n",
    "  ------------------------------------------------------------------------------\n",
    "  Outout:\n",
    "  ------------------------------------------------------------------------------\n",
    "  dados: Datafame com coluna tratado\n",
    "  ------------------------------------------------------------------------------\n",
    "  ******************************************************************************\n",
    "  '''\n",
    "  dados[\"tratados\"] = dados[\"front\"]\n",
    "\n",
    "  retirar = re.compile(\"\\[anki:play:q:0\\]\")\n",
    "  linhas = []\n",
    "  for linha in dados[\"tratados\"]:    \n",
    "    linhas.append(re.sub(retirar, '', linha))\n",
    "  dados[\"tratados\"] = linhas\n",
    "\n",
    "  retirar = re.compile(\"\\[Grammar\\]\")\n",
    "  linhas = []\n",
    "  for linha in dados[\"tratados\"]:    \n",
    "    linhas.append(re.sub(retirar, '', linha))\n",
    "  dados[\"tratados\"] = linhas\n",
    "\n",
    "  retirar = re.compile(\"\\[Inglês Britânico\\]\")\n",
    "  linhas = []\n",
    "  for linha in dados[\"tratados\"]:    \n",
    "    linhas.append(re.sub(retirar, '', linha))\n",
    "  dados[\"tratados\"] = linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "8ecR5yLaeriT"
   },
   "outputs": [],
   "source": [
    "def make_date(file_name):\n",
    "  '''\n",
    "  ******************************************************************************\n",
    "  make_date: Le o nome do arquivo e retorna a data.\n",
    "  ------------------------------------------------------------------------------\n",
    "  Input:\n",
    "  ------------------------------------------------------------------------------\n",
    "  file_name: nome do arquivo\n",
    "  ------------------------------------------------------------------------------\n",
    "  Outout:\n",
    "  ------------------------------------------------------------------------------\n",
    "  Data no formato 00/00/0000\n",
    "  ------------------------------------------------------------------------------\n",
    "  ******************************************************************************\n",
    "  '''\n",
    "  return file_name[file_name.index(\"anki\")+5:file_name.index(\".\")].replace(\"_\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "JpPq4_iyc2K5"
   },
   "outputs": [],
   "source": [
    "files = \"dados/anki_11_02_2021.txt\", \"dados/anki_20_02_2021.txt\", \"dados/anki_08_03_2021.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyCdpdAFMzqg",
    "outputId": "196cdb0d-207e-4d0f-d682-649553583bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data                     : 11/02/2021\n",
      "Total de palavras        : 22722\n",
      "Total de palavras unicas : 4862\n",
      "\n",
      "data                     : 20/02/2021\n",
      "Total de palavras        : 23838\n",
      "Total de palavras unicas : 4980\n",
      "\n",
      "data                     : 08/03/2021\n",
      "Total de palavras        : 27007\n",
      "Total de palavras unicas : 5396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name in files:\n",
    "  dados = pd.read_csv(file_name, sep=\"\\t\", header=None, names = [\"front\", \"back\"])\n",
    "  substituir(dados)\n",
    "  palavras = palvavra_separadas(dados)\n",
    "  total_palavras = len(palavras)\n",
    "  palavras_unicas = gera_palavras_unicas(palavras)\n",
    "  total_de_palavras_unicas = len(palavras_unicas)\n",
    "  print(f\"data                     : {make_date(file_name)}\")\n",
    "  print(f\"Total de palavras        : {total_palavras}\")\n",
    "  print(f\"Total de palavras unicas : {total_de_palavras_unicas}\")\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Anki.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
